{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exploring the Capabilities of LLM Models\n",
    "\n",
    "In this notebook, I aim to evaluate and compare the capabilities of two large language models (LLMs):\n",
    "\n",
    "1. **Codestral22B**\n",
    "   A state-of-the-art model designed for advanced code generation and natural language understanding tasks.\n",
    "\n",
    "2. **Llama 3.1-8B**\n",
    "   A highly efficient and compact model optimized for general-purpose language tasks with an 8-billion parameter architecture.\n",
    "\n",
    "The goal is to analyze their performance across various tasks, including but not limited to:\n",
    "\n",
    "- Code generation and completion\n",
    "- Natural language understanding\n",
    "- Contextual reasoning\n",
    "- Problem-solving capabilities\n",
    "\n",
    "This comparison will help identify the strengths and weaknesses of each model and provide insights into their practical applications."
   ],
   "id": "e998a0cbbfb16865"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI-Powered Programming Tutor with RAG\n",
    "\n",
    "This project focuses on building an AI-powered programming tutor designed to assist students in understanding code and solving problems. The tutor leverages **Retrieval-Augmented Generation (RAG)** to provide accurate and personalized explanations grounded in real university materials, such as:\n",
    "\n",
    "- Past assignments\n",
    "- Lecture notes\n",
    "- Tutorials`\n",
    "\n",
    "The system integrates two large language models (LLMs), **Codestral22B** and **Llama 3.1-8B**, to evaluate their performance in generating solutions and explanations for programming-related queries. The goal is to determine which model provides better support for students in a university setting.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Personalized Explanations**: Tailored responses based on retrieved university materials.\n",
    "- **Code Understanding**: Helps students debug and understand code snippets.\n",
    "- **Problem Solving**: Provides step-by-step solutions to programming problems.\n",
    "- **Model Comparison**: Evaluates the performance of Codestral22B and Llama 3.1-8B.\n",
    "\n",
    "---\n",
    "\n"
   ],
   "id": "564c5ae159c2e7d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Basically, I will try to implement and test Codestral22B and Llama 3.1-8B",
   "id": "ac466a7a41b538cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:18:59.107633Z",
     "start_time": "2025-05-23T15:18:59.087432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from os.path import exists\n",
    "\n",
    "import requests\n",
    "\n",
    "#API endpoint exposed in Lm studio\n",
    "url = \"http://localhost:1234/v1/chat/completions\"\n",
    "\n",
    "#model ID\n",
    "model_id = \"meta-llama-3.1-8b-instruct\"\n",
    "\n",
    "headers={\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Authorization\" :\"Bearer lm-studio\" #Dummy API key\n",
    "}\n",
    "\n",
    "# messages: [ #keep conversation history\n",
    "#                 {\"role\":\"user\", #what you type, only sends current prompt\n",
    "#                  \"content\":user_input}\n",
    "#             ]\n",
    "\n",
    "#Keep the message history\n",
    "\n",
    "#History file path, to keep conversation\n",
    "history_file = \"chat-history.json\"\n",
    "def save_history(messages):\n",
    "    # Load existing history if the file exists\n",
    "    if exists(history_file):\n",
    "        with open(history_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_history = json.load(f)\n",
    "            if isinstance(full_history, list):\n",
    "                pass\n",
    "            else:\n",
    "                full_history = [full_history]\n",
    "    else:\n",
    "        full_history = []\n",
    "\n",
    "    # Add this session with timestamp\n",
    "    full_history.append({\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"conversation\": messages\n",
    "    })\n",
    "\n",
    "    # Save the full conversation list\n",
    "    with open(history_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(full_history, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "#Prompt loop\n",
    "def chat():\n",
    "    print(\" Talk to LLaMA 3.1 (type 'exit' to quit)\\n\")\n",
    "    messages = [\n",
    "    {\"role\": \"system\", #Sets the intial behavior, the text below\n",
    "     \"content\": \"You are a helpful programming tutor.\"}\n",
    "] #Messages reset each time\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\" You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            #save chat history\n",
    "            save_history(messages)\n",
    "            print(f\"\\n Conversation saved to {history_file}\")\n",
    "            break\n",
    "\n",
    "        # Add user message\n",
    "        messages.append({\"role\": \"user\",\n",
    "                         \"content\": user_input})\n",
    "\n",
    "        payload = {\n",
    "            \"model\": model_id,#id of model\n",
    "            \"messages\": messages,#chat history to preserve context\n",
    "            \"temperature\": 0.7 #control creativiy\n",
    "        }\n",
    "        print(\"Your question is: \")\n",
    "        print(user_input)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        try:#send request to lm api\n",
    "            response = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                answer = data['choices'][0]['message']['content'].strip()\n",
    "\n",
    "                # Add assistant message\n",
    "                messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "                print(\"\\n LLaMA:\", flush=True)\n",
    "                print(answer, flush=True)\n",
    "                print(\"-\" * 60 + \"\\n\")\n",
    "\n",
    "            else:\n",
    "                print(f\" Error {response.status_code}: {response.text}\\n\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\" Connection error:\", e)\n",
    "            break\n"
   ],
   "id": "563b527baebdc0d7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:20:17.755965Z",
     "start_time": "2025-05-23T15:18:59.116372Z"
    }
   },
   "cell_type": "code",
   "source": "chat()",
   "id": "64c4f903e35e8b0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Talk to LLaMA 3.1 (type 'exit' to quit)\n",
      "\n",
      "Your question is: \n",
      "Tell me something about methaeuristics\n",
      "\n",
      "\n",
      "\n",
      " LLaMA:\n",
      "Metaheuristics are high-level algorithms that use lower-level heuristics to find good solutions to complex optimization problems. They're often used when the problem is too hard or too time-consuming for traditional methods.\n",
      "\n",
      "Some key characteristics of metaheuristics include:\n",
      "\n",
      "1. **Global Search**: Metaheuristics are designed to explore the entire solution space, rather than just a local neighborhood.\n",
      "2. **Heuristic Search**: Metaheuristics use heuristics (e.g., proximity measures) to guide the search process.\n",
      "3. **Randomization**: Many metaheuristics incorporate randomness to escape local optima and improve exploration.\n",
      "4. **Iterative Improvement**: Metaheuristics often involve iteratively improving a solution through some form of transformation or mutation.\n",
      "\n",
      "Common examples of metaheuristics include:\n",
      "\n",
      "1. **Simulated Annealing (SA)**: A probabilistic algorithm that uses temperature schedules to control the acceptance of new solutions.\n",
      "2. **Genetic Algorithms (GAs)**: Inspired by natural selection and genetics, GAs use crossover and mutation operators to evolve better solutions.\n",
      "3. **Tabu Search (TS)**: A memory-based algorithm that stores previously visited solutions to avoid cycling through local optima.\n",
      "4. **Ant Colony Optimization (ACO)**: A swarm-intelligence approach inspired by ants searching for food sources.\n",
      "5. **Particle Swarm Optimization (PSO)**: A population-based algorithm that uses social interaction and cooperation to converge towards the optimal solution.\n",
      "\n",
      "Metaheuristics are particularly useful in cases where:\n",
      "\n",
      "* The problem is NP-hard or NP-complete.\n",
      "* Traditional methods (e.g., linear programming) fail due to complex constraints or non-linear relationships.\n",
      "* The number of variables or solutions is too large for exhaustive search.\n",
      "\n",
      "When choosing a metaheuristic, consider factors like:\n",
      "\n",
      "* Problem characteristics: Understand the specific requirements and constraints of your problem.\n",
      "* Algorithm properties: Consider the trade-offs between exploration, exploitation, and convergence speed.\n",
      "* Computational resources: Balance between solution quality and computational time.\n",
      "\n",
      "Do you have any specific questions about metaheuristics or would you like to discuss a particular application?\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      " Conversation saved to chat-history.json\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1: Load the Datasets\n",
    "## 1.  OpenMathInstruct-1 (from Hugging Face)\n",
    "- This dataset contains 1.8 million math problem-solution pairs, making it ideal for enhancing mathematical reasoning in LLMs."
   ],
   "id": "e783b140318afef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:20:17.836008Z",
     "start_time": "2025-05-23T15:20:17.817005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from datasets import load_dataset\n",
    "# from IPython import get_ipython\n",
    "# from IPython.display import display\n",
    "#\n",
    "# #Load training split\n",
    "# dataset = load_dataset(\"nvidia/OpenMathInstruct-1\", split=\"train\")\n",
    "#\n",
    "# first_element = next(iter(dataset))\n",
    "#\n",
    "# print(first_element)\n",
    "\n",
    "#Give up on it, waaaay to much data in dataset"
   ],
   "id": "6e22bd11d37f410d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Small & Clean Math Datasets\n",
    "## 1. GSM8K\n",
    "- Size: ~8.5K problems\n",
    "\n",
    "- Focus: Grade school math word problems\n",
    "\n",
    "- Good for: step-by-step reasoning, small LLM finetuning"
   ],
   "id": "29e5ef5f3ac8e47f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:20:22.540871Z",
     "start_time": "2025-05-23T15:20:17.916011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "first_element = next(iter(dataset))\n",
    "\n",
    "print(first_element)"
   ],
   "id": "103b6abd4efba505",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Computer Science Theory QA Dataset (from Kaggle)\n",
    "- This dataset offers a comprehensive collection of theoretical computer science questions, suitable for training chatbots and QA systems."
   ],
   "id": "74dbff67600058c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:20:22.571870Z",
     "start_time": "2025-05-23T15:20:22.550873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"intents.json\", \"r\") as f:\n",
    "    intents_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame if needed\n",
    "df = pd.json_normalize(intents_data[\"intents\"])\n",
    "print(df.head())"
   ],
   "id": "652d5f795177fbea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tag                                           patterns  \\\n",
      "0    abstraction  [Explain data abstraction., What is data abstr...   \n",
      "1          error  [What is a syntax error, Explain syntax error,...   \n",
      "2  documentation  [Explain program documentation. Why is it impo...   \n",
      "3        testing                        [What is software testing?]   \n",
      "4  datastructure             [How do you explain a data structure?]   \n",
      "\n",
      "                                           responses  \n",
      "0  [Data abstraction is a technique used in compu...  \n",
      "1  [A syntax error is an error in the structure o...  \n",
      "2  [Program documentation is written information ...  \n",
      "3  [Software testing is the process of evaluating...  \n",
      "4  [A data structure is a way of organizing and s...  \n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
